{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table Extraction Case Study\n",
    "### AAIC Self Case Study II\n",
    "### Author: Soumya De\n",
    "\n",
    "<hr>\n",
    "\n",
    "## 7. Final Pipeline Method\n",
    "\n",
    "We will now make use of the compressed tflite model that we have obtained in the previous section and design our final pipeline, that is from getting an image (as a file on the disk) to obtain a csv (also as file on the disk) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing dependencies\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import csv\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from time import strftime\n",
    "import pytesseract\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Model\n",
    "\n",
    "import requests\n",
    "from io import BytesIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining helper functions \n",
    "def load_interpreter(model_path=None):\n",
    "    \"\"\"\n",
    "    This function loads a tflite model interpreter \n",
    "    \"\"\"\n",
    "    if model_path is None:\n",
    "        model_path = os.path.sep.join(['final_model', 'tablenet_densenet121_lite.tflite'])\n",
    "    interpreter = tf.lite.Interpreter(model_path=model_path)\n",
    "    interpreter.allocate_tensors()\n",
    "    return interpreter \n",
    "\n",
    "def adjust(new_rows, maxi):\n",
    "    \"\"\"\n",
    "    A function to set all with maxi number of columns\n",
    "    for making csv compatible\n",
    "    \"\"\"\n",
    "    rows = []\n",
    "    for each_row in new_rows:\n",
    "        if len(each_row) < maxi:\n",
    "            for i in range(maxi - len(each_row)):\n",
    "                each_row.append(\"-\")\n",
    "        rows.append(each_row)\n",
    "    return rows\n",
    "\n",
    "def text2csv(text):\n",
    "    \"\"\"\n",
    "    This funtion transorms a text with newline and spaces to\n",
    "    a csv that treats the spaces in the text as comma and newlines as carriage return\n",
    "    \"\"\"\n",
    "    rows = text.split('\\n')\n",
    "    new_rows = []\n",
    "    maxi = 0\n",
    "    for each_row in rows:\n",
    "        temp_row = each_row.split()\n",
    "        if maxi < len(temp_row):\n",
    "            maxi = len(temp_row)\n",
    "        new_rows.append(temp_row)\n",
    "    new_rows = adjust(new_rows, maxi)\n",
    "    header = ['column_{}'.format(i) for i in range(maxi)]\n",
    "    tstr = strftime(\"%Y%m%d-%H%M\")\n",
    "    temp_dir = os.path.join('output', 'temporary_files')\n",
    "    if not os.path.exists(temp_dir):\n",
    "        os.makedirs(temp_dir)\n",
    "    temp_file = os.path.join(temp_dir, 'temp_{}.csv'.format(tstr))\n",
    "\n",
    "    with open(temp_file, 'w') as f:\n",
    "        csvwriter = csv.writer(f)\n",
    "        csvwriter.writerow(header)\n",
    "        csvwriter.writerows(new_rows)\n",
    "    return temp_file\n",
    "\n",
    "def append_offset(name, offset):\n",
    "    \"\"\"\n",
    "    This function is used for assigning a name with offset if a file with the same name exists\n",
    "    It takes a filename and a offset and returns a valid equivalent name with offset number\n",
    "    \n",
    "    Example :\n",
    "    # assume two variables \n",
    "    name = 'python.py'\n",
    "    offset = '2'\n",
    "    append_offset(name, offset)\n",
    "    \n",
    "    # The above invocation will return string as\n",
    "    # 'python_2.py'\n",
    "    \"\"\"\n",
    "    fname, extension = name.split('.')\n",
    "    fname = ''.join([fname, '_', offset, '.', extension])\n",
    "    return fname\n",
    "\n",
    "def render(mask):\n",
    "  mask = tf.argmax(mask, axis=-1)\n",
    "  mask = mask[..., tf.newaxis]\n",
    "  return mask[0]\n",
    "\n",
    "def visualize(image):\n",
    "    plt.figure(figsize=(15, 15))\n",
    "    title = 'Cropped Table'\n",
    "    plt.title(title)\n",
    "    plt.imshow(tf.keras.preprocessing.image.array_to_img(image))\n",
    "    plt.axis('off')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def final(img_path, output_dir='temp_output', show_table=False):\n",
    "    \n",
    "    \n",
    "    #response = requests.get(url)\n",
    "    #img = Image.open(BytesIO(response.content))\n",
    "    \n",
    "    interpreter = load_interpreter()\n",
    "    image_orig = Image.open(img_path)\n",
    "    original_dim = image_orig.size\n",
    "    image = image_orig.resize((512,512))\n",
    "    np_image = np.asarray(image)/255.0\n",
    "    np_image = np_image.astype(np.float32)\n",
    "    np_image = np.expand_dims(np_image, axis=0)\n",
    "\n",
    "    ip_d = interpreter.get_input_details()[0]\n",
    "    op_d = interpreter.get_output_details()[0]\n",
    "\n",
    "    interpreter.set_tensor(ip_d['index'], np_image)\n",
    "    interpreter.invoke()\n",
    "    \n",
    "    tab_mask = interpreter.get_tensor(op_d['index'])\n",
    "\n",
    "    \n",
    "    tab_mask = np.squeeze(render(tab_mask).numpy())\n",
    "\n",
    "    tab_mask = Image.fromarray(np.uint8(tab_mask))\n",
    "    tab_mask = tab_mask.resize(original_dim)\n",
    "\n",
    "    tab_mask = np.array(tab_mask)\n",
    "\n",
    "    image_orig = image_orig\n",
    "    x, y, w, h = cv2.boundingRect(tab_mask)\n",
    "    tab = image_orig.crop((x, y, x+w, y+h))\n",
    "    \n",
    "\n",
    "    text = pytesseract.image_to_string(tab)\n",
    "    text = text.strip()\n",
    "    text = re.sub(\"[\\r\\n]+\", \"\\r\\n\", text)\n",
    "    csv = text2csv(text)\n",
    "    csv_fname = img_path.split(os.path.sep)[-1].replace('png', 'csv')\n",
    "    dest_dir = os.path.join(output_dir)\n",
    "    if not os.path.exists(dest_dir):\n",
    "        os.makedirs(dest_dir)\n",
    "    dest = os.path.join(dest_dir, csv_fname)\n",
    "    # if file already exists in the temp directory it will save the csv \n",
    "    # by appending some offset to the filename before extension\n",
    "    try:\n",
    "        os.rename(csv, dest)\n",
    "    except:\n",
    "        f_save = 'fail'\n",
    "        i=2\n",
    "        while(f_save=='fail'):\n",
    "            name_off = str(i)\n",
    "            try:\n",
    "                dest = os.path.join(dest_dir, append_offset(csv_fname,name_off))\n",
    "                os.rename(csv, dest)\n",
    "                f_save = 'pass'\n",
    "            except:\n",
    "                i += 1\n",
    "\n",
    "    if show_table:\n",
    "        visualize(tab)\n",
    "\n",
    "    return dest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference using the final function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Could not open 'final_model\\tablenet_densenet121_lite.tflite'.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_11308/2778145320.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mcsv_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfinal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshow_table\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcsv_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_11308/660406149.py\u001b[0m in \u001b[0;36mfinal\u001b[1;34m(img_path, output_dir, show_table)\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;31m#img = Image.open(BytesIO(response.content))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m     \u001b[0minterpreter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_interpreter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m     \u001b[0mimage_orig\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0moriginal_dim\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimage_orig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_11308/466125673.py\u001b[0m in \u001b[0;36mload_interpreter\u001b[1;34m(model_path)\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mmodel_path\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m         \u001b[0mmodel_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msep\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'final_model'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'tablenet_densenet121_lite.tflite'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m     \u001b[0minterpreter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlite\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mInterpreter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m     \u001b[0minterpreter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mallocate_tensors\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minterpreter\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\lite\\python\\interpreter.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, model_path, model_content, experimental_delegates, num_threads, experimental_op_resolver_type, experimental_preserve_all_tensors)\u001b[0m\n\u001b[0;32m    454\u001b[0m       ]\n\u001b[0;32m    455\u001b[0m       self._interpreter = (\n\u001b[1;32m--> 456\u001b[1;33m           _interpreter_wrapper.CreateWrapperFromFile(\n\u001b[0m\u001b[0;32m    457\u001b[0m               \u001b[0mmodel_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop_resolver_id\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcustom_op_registerers_by_name\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    458\u001b[0m               custom_op_registerers_by_func, experimental_preserve_all_tensors))\n",
      "\u001b[1;31mValueError\u001b[0m: Could not open 'final_model\\tablenet_densenet121_lite.tflite'."
     ]
    }
   ],
   "source": [
    "#img_path = os.path.join('data', 'ICDAR 2017', 'table_images', 'POD_0011.png')\n",
    "img_path = os.path.join('1.png')\n",
    "\n",
    "\n",
    "csv_path = final(img_path, show_table=True)\n",
    "df = pd.read_csv(csv_path)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ef5b0ef59d97884fc4d38c7113842b178f3d8e2fcb1f37e35bd9276ea971cee9"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
